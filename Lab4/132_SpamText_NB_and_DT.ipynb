{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SpamText-NB and DT.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Purvsoni/132_PurvSoni/blob/main/Lab4/132_SpamText_NB_and_DT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUgLRWfKl13U",
        "outputId": "e5a2f2ef-a278-4e0b-b041-0a55265c048f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrZevCPJ92HG"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rmYBjsyCv3K"
      },
      "source": [
        "dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/ML/Lab4/spam.csv') \n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkvmsbgkNRe4"
      },
      "source": [
        "## Analysis\n",
        "\n",
        "To analyze the text data, we have to turn the words into numerical numbers. \n",
        "We have multiple choices to accomplish this step: \n",
        "\n",
        "1) Binary Term Frequency :  count presence(1) or absence(0) for term in document\n",
        "\n",
        "2) Bag of Words Frequency:  captures the frequency of term in document\n",
        "\n",
        "3) Term Frequency: \n",
        "\n",
        "4) TFIDF :\n",
        "\n",
        "in this way, if a term appears frequently in a document, it’s important; if a term appears in many documents, it’s not a unique identifier.\n",
        "\n",
        "useful links :\n",
        "\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
        "- https://towardsdatascience.com/tf-idf-for-document-ranking-from-scratch-in-python-on-real-world-dataset-796d339a4089\n",
        "- https://machinelearningmastery.com/gentle-introduction-bag-words-model/\n",
        "- https://towardsdatascience.com/hacking-scikit-learns-vectorizers-9ef26a7170af\n",
        "- https://towardsdatascience.com/top-5-word-tokenizers-that-every-nlp-data-scientist-should-know-45cc31f8e8b9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jR0K9BFZl06C",
        "outputId": "9178f030-cc30-486f-e1f2-a5ce88fcb5de"
      },
      "source": [
        "print(\"\\nData :\\n\",dataset)\n",
        "print(\"\\nData statistics\\n\",dataset.info())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data :\n",
            "         v1                                                 v2\n",
            "0      ham  Go until jurong point, crazy.. Available only ...\n",
            "1      ham                      Ok lar... Joking wif u oni...\n",
            "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3      ham  U dun say so early hor... U c already then say...\n",
            "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
            "...    ...                                                ...\n",
            "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
            "5568   ham              Will �_ b going to esplanade fr home?\n",
            "5569   ham  Pity, * was in mood for that. So...any other s...\n",
            "5570   ham  The guy did some bitching but I acted like i'd...\n",
            "5571   ham                         Rofl. Its true to its name\n",
            "\n",
            "[5572 rows x 2 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5572 entries, 0 to 5571\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   v1      5572 non-null   object\n",
            " 1   v2      5571 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 87.2+ KB\n",
            "\n",
            "Data statistics\n",
            " None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zagIletl06G",
        "outputId": "33105796-24e8-4f93-8299-4a4f65e40db2"
      },
      "source": [
        "dataset.dropna(how='any',inplace=True)\n",
        "print(dataset.isnull().sum())\n",
        "dataset.drop_duplicates(inplace=True)\n",
        "print(dataset.duplicated().any())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "v1    0\n",
            "v2    0\n",
            "dtype: int64\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbhXzh5ONQ5R"
      },
      "source": [
        "# Preprocessing"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-nZMiJrl06J"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import nltk\n",
        "import string\n",
        "import re\n",
        "import random"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "tVPZteMTl06L"
      },
      "source": [
        "re.findall(r\"[a-z]+\", \"123ram=*kisanw217-+/\") "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYs4X8-jl06N"
      },
      "source": [
        "def stemWords(list1):\n",
        "    #     stemmer=nltk.stem.PorterStemmer()\n",
        "    stemmer=nltk.stem.SnowballStemmer('english')\n",
        "    #     leminizer.lemmatize(word)\n",
        "    #     stemmer = nltk.stem.ISRIStemmer()\n",
        "    #     leminizer = nltk.stem.WordNetLemmatizer()\n",
        "    #     stemmer = nltk.stem.LancasterStemmer()\n",
        "    \n",
        "    words=[]\n",
        "    for text in list1:\n",
        "        for word in re.findall(r\"[a-z]+\",text):\n",
        "            if (len(word)>2 and word not in string.punctuation):\n",
        "                words.append(stemmer.stem(word))\n",
        "    return words\n",
        "    \n",
        "def my_tokenizer(text):\n",
        "#     tokens=nltk.tokenize.TreebankWordTokenizer().tokenize(text)\n",
        "#     tokens=nltk.tokenize.word_tokenize(text)\n",
        "    tokens =nltk.tokenize.wordpunct_tokenize(text)\n",
        "    \n",
        "    newtokens= stemWords(tokens)\n",
        "    \n",
        "    return newtokens\n",
        "\n",
        "def convert_to_sparse_pandas(df, exclude_columns=[]):\n",
        "    \"\"\"\n",
        "    Converts columns of a data frame into SparseArrays and returns the data frame with transformed columns.\n",
        "    Use exclude_columns to specify columns to be excluded from transformation.\n",
        "    :param df: pandas data frame\n",
        "    :param exclude_columns: list\n",
        "        Columns not be converted to sparse\n",
        "    :return: pandas data frame\n",
        "    \"\"\"\n",
        "    df = pd.DataFrame()\n",
        "    exclude_columns = set(exclude_columns)\n",
        "\n",
        "    for (columnName, columnData) in df.iteritems():\n",
        "        if columnName in exclude_columns:\n",
        "            continue\n",
        "        df[columnName] = pd.arrays.SparseArray(columnData.values, dtype='uint8')\n",
        "\n",
        "    return df"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMy4kWnhmS2G",
        "outputId": "e4617f9e-1e42-4cd9-81f1-e9239ec0493b"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "vklk2JBAl06P"
      },
      "source": [
        "my_tokenizer(dataset['v2'][0])"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8fTTIdQl06Q",
        "outputId": "f4adbfbe-4b24-4e3f-ffad-a7fab266c78c"
      },
      "source": [
        "vectorizer = CountVectorizer(stop_words=nltk.corpus.stopwords.words('english'),tokenizer=my_tokenizer,ngram_range=(1,1))\n",
        "X = vectorizer.fit_transform(dataset['v2'])\n",
        "tokens=vectorizer.get_feature_names()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'becaus', 'befor', 'doe', 'dure', 'onc', 'onli', 'ourselv', 'themselv', 'veri', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsFpqj5Al06Q",
        "outputId": "f7c0cfe6-3793-435f-cb22-b3173b75dbff"
      },
      "source": [
        "len(tokens)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5847"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qwok2hsjl06R"
      },
      "source": [
        "Labels = dataset['v1']\n",
        "Data = pd.DataFrame(data=X.toarray(),columns=tokens)\n",
        "SparseData = Data.astype(pd.SparseDtype(np.int16))\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBmsFBoel06T",
        "outputId": "7da3a55b-7d44-45a4-a8eb-b14ef89b56e4"
      },
      "source": [
        "r = random.randint(0,Data.shape[1]-1)\n",
        "print(r)\n",
        "print(np.unique(Data.iloc[:,r]))\n",
        "print(Data.memory_usage().sum()*pow(10,-6)*3, \" mb\")\n",
        "print(dataset.memory_usage().sum()*pow(10,-6)*3,\" mb\")\n",
        "print(SparseData.memory_usage().sum()*pow(10,-6)*3,\" mb\")\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1017\n",
            "[0 1]\n",
            "724.513848  mb\n",
            "0.37173599999999996  mb\n",
            "0.679704  mb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2qJLGNtl06U"
      },
      "source": [
        "encoder = LabelEncoder()\n",
        "Labels = encoder.fit_transform(Labels)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pf-43vEil06U",
        "outputId": "e30f920f-5533-492f-d25d-d95d4eaf04ee"
      },
      "source": [
        "print(Data.shape)\n",
        "print(SparseData.shape)\n",
        "print(dataset.shape)\n",
        "print(Labels.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5163, 5847)\n",
            "(5163, 5847)\n",
            "(5163, 2)\n",
            "(5163,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "O1Hwq0SSl06V"
      },
      "source": [
        "print(Labels)\n",
        "print(SparseData)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53xSU7ayl06W"
      },
      "source": [
        "# Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9P_M450ql06W"
      },
      "source": [
        "from sklearn.metrics import classification_report\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9vB3hKHIEFr"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data_train, data_test, target_train, target_test = train_test_split(SparseData,\n",
        "                        Labels, test_size = 0.30, random_state = 132)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcC9U7_DHw03"
      },
      "source": [
        "**Naive Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZAmSYVKIWG5"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1x-8CRXl06Y"
      },
      "source": [
        "data_train, data_test, target_train, target_test = train_test_split(Data,\n",
        "                        Labels, test_size = 0.30, random_state = 132)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Vzi9E5xl06Z",
        "outputId": "86d39e12-58be-4e7e-9e04-356e026b9b43"
      },
      "source": [
        "gnb = GaussianNB()\n",
        "gnb.fit(data_train,target_train)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(priors=None, var_smoothing=1e-09)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGy3kLnhl06a"
      },
      "source": [
        "target_pred = gnb.predict(data_test)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahGFjiyPl06a",
        "outputId": "e9e94b29-df97-4cf9-ff0a-a48d052eb5b4"
      },
      "source": [
        "print(classification_report(target_test,target_pred))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.85      0.91      1356\n",
            "           1       0.46      0.88      0.60       193\n",
            "\n",
            "    accuracy                           0.85      1549\n",
            "   macro avg       0.72      0.87      0.76      1549\n",
            "weighted avg       0.92      0.85      0.87      1549\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYu4_PnbIxfw"
      },
      "source": [
        "**Decision Tree**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqjGef-FIw7U"
      },
      "source": [
        "from sklearn import tree"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GjQhFBRl06c"
      },
      "source": [
        "mytree = tree.DecisionTreeClassifier(random_state=132,max_depth=20,max_leaf_nodes=132)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dmSs0Ndl06c",
        "outputId": "694004b9-fa49-4f1a-ab9f-1c9df34bdd07"
      },
      "source": [
        "mytree.fit(data_train,target_train)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=20, max_features=None, max_leaf_nodes=132,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=132, splitter='best')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZlfTA91l06d"
      },
      "source": [
        "target_pred=mytree.predict(data_test)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrtQZQhdl06e",
        "outputId": "b0309762-cfeb-499a-a8b8-f94cf83cdedb"
      },
      "source": [
        "print(classification_report(target_test,target_pred))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98      1356\n",
            "           1       0.89      0.78      0.83       193\n",
            "\n",
            "    accuracy                           0.96      1549\n",
            "   macro avg       0.93      0.88      0.90      1549\n",
            "weighted avg       0.96      0.96      0.96      1549\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3i5VpsczbgsS"
      },
      "source": [
        "**Optional Exercise:**\n",
        "Try this on full spam.csv file and bigram matching instead of unigram matching "
      ]
    }
  ]
}