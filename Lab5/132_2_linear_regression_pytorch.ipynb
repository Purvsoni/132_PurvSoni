{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2-linear-regression-pytorch.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Purvsoni/132_PurvSoni/blob/main/Lab5/2_linear_regression_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "v0BtAX1--7l_"
      },
      "source": [
        "# Import Numpy & PyTorch\n",
        "import numpy as np\n",
        "import torch"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "ecc6e79cdfb6a8ca882895ccc895b61b960b0a04",
        "id": "i1HSrBDb-7t9"
      },
      "source": [
        "## Linear Regression Model using PyTorch built-ins\n",
        "\n",
        "Let's re-implement the same model using some built-in functions and classes from PyTorch.\n",
        "\n",
        "And now using two different targets: Apples and Oranges"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "ce66cf0d09a3f38bf2f00ea40418c56d98f1f814",
        "id": "iXiEK54j-7t-"
      },
      "source": [
        "# Imports\n",
        "import torch.nn as nn"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "74bb18bd01ac809079eeb8d05695206e8ba02069",
        "id": "wCsxgTWO-7uM"
      },
      "source": [
        "# Input (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43], [91, 88, 64], [87, 134, 58], [102, 43, 37], [69, 96, 70], [73, 67, 43], [91, 88, 64], [87, 134, 58], [102, 43, 37], [69, 96, 70], [73, 67, 43], [91, 88, 64], [87, 134, 58], [102, 43, 37], [69, 96, 70]], dtype='float32')\n",
        "# Targets (apples, oranges)\n",
        "targets = np.array([[56, 70], [81, 101], [119, 133], [22, 37], [103, 119], \n",
        "                    [56, 70], [81, 101], [119, 133], [22, 37], [103, 119], \n",
        "                    [56, 70], [81, 101], [119, 133], [22, 37], [103, 119]], dtype='float32')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d94b355f55250e9c7dcff668920f02d7c5c04925",
        "id": "nJRlm4-N-7uY"
      },
      "source": [
        "X = torch.from_numpy(inputs)\n",
        "Y = torch.from_numpy(targets)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrEFb0fzo2qT"
      },
      "source": [
        "\n",
        "$$\n",
        "\\hspace{2.5cm} X \\hspace{1.1cm} \\times \\hspace{1.2cm} W^T \\hspace{1.2cm}  + \\hspace{1cm} b \\hspace{2cm}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\left[ \\begin{array}{cc}\n",
        "73 & 67 & 43 \\\\\n",
        "91 & 88 & 64 \\\\\n",
        "\\vdots & \\vdots & \\vdots \\\\\n",
        "69 & 96 & 70\n",
        "\\end{array} \\right]\n",
        "%\n",
        "\\times\n",
        "%\n",
        "\\left[ \\begin{array}{cc}\n",
        "w_{11}& w_{21} \\\\ \n",
        "w_{12} & w_{22} \\\\\n",
        "w_{13} & w_{23}\\\\\n",
        "\\end{array} \\right]\n",
        "%\n",
        "+\n",
        "%\n",
        "\\left[ \\begin{array}{cc}\n",
        "b_{1} & b_{2}\\\\\n",
        "\\end{array} \\right]\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "a0665466eb5401f40a816b323a34450b2c052c41",
        "id": "O6JT5Ng6-7uj"
      },
      "source": [
        "### Dataset and DataLoader\n",
        "\n",
        "We'll create a `TensorDataset`, which allows access to rows from `inputs` and `targets` as tuples. We'll also create a DataLoader, to split the data into batches while training. It also provides other utilities like shuffling and sampling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "206f5fd0473386476b23477bf38d2c327b6376c9",
        "id": "iGYdbuWc-7ul"
      },
      "source": [
        "# Import tensor dataset & data loader\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "c47a4f2f86fda3918094e01cf7ab0698bbb5acc7",
        "id": "LY_cq6Bf-7ux"
      },
      "source": [
        "# Define dataset\n",
        "dataset = torch.utils.data.TensorDataset(X,Y)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "0a2f69126319d738b82ae67d5d404ecd6161bfac",
        "id": "I-_dMpco-7u-"
      },
      "source": [
        "# Define data loader\n",
        "trainloader = torch.utils.data.DataLoader(dataset,batch_size=10)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "276a262e1b9e3a048bcd32989013f9c501c59037",
        "id": "Dq8gUbVx-7vK"
      },
      "source": [
        "### nn.Linear\n",
        "Instead of initializing the weights & biases manually, we can define the model using `nn.Linear`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "59da3506559a0640d80d18f77b02726a1757be2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKa873ZD-7vN",
        "outputId": "ebabfbe6-025a-4fce-a7a2-4d30bdf72279"
      },
      "source": [
        "# Define model\n",
        "model = nn.Linear(X.shape[1],Y.shape[1])\n",
        "print(model.state_dict())\n",
        "model.parameters()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('weight', tensor([[ 0.4984,  0.3557,  0.5598],\n",
            "        [-0.4223, -0.4953, -0.4096]])), ('bias', tensor([ 0.2977, -0.2929]))])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object Module.parameters at 0x7f504ade92d0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "b3a4a8c499a4680f2533329712de034671dd1cdd",
        "id": "rku14lz3-7vX"
      },
      "source": [
        "### Optimizer\n",
        "Instead of manually manipulating the weights & biases using gradients, we can use the optimizer `optim.SGD`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "1848398bd1ced8c25a7bb55612cf32a774500280",
        "id": "Yd4H-T8g-7va"
      },
      "source": [
        "# Define optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=1e-4)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "28cbe62be55010bd11b31d819cff38da5a772b18",
        "id": "V2ktEA-C-7vl"
      },
      "source": [
        "### Loss Function\n",
        "Instead of defining a loss function manually, we can use the built-in loss function `mse_loss`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "69d7f4e8e27ccd077f711da27f8bede8aa711893",
        "id": "TF2xmzgO-7vo"
      },
      "source": [
        "# Import nn.functional\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "a02ff888ed4be720fd9ca376022d8fdcf2559683",
        "id": "hSgxvr8N-7vz"
      },
      "source": [
        "# Define loss function\n",
        "loss_fn = F.mse_loss"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "e833614a69ff18c554a3d89f643ae2f11e0260f6",
        "id": "9jbPdkiO-7wM"
      },
      "source": [
        "### Train the model\n",
        "\n",
        "We are ready to train the model now. We can define a utility function `fit` which trains the model for a given number of epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "128bc7260221f5338edf8b503c75f0c7d1cce7e8",
        "id": "zDnWui7g-7wP"
      },
      "source": [
        "# Define a utility function to train the model\n",
        "def fit(num_epochs, model, loss_fn, opt):\n",
        "    for epoch in range(num_epochs):\n",
        "        for xb,yb in trainloader:\n",
        "            # Generate predictions\n",
        "            pred = model(xb)\n",
        "            loss = loss_fn(yb,pred)\n",
        "            # Perform gradient descent\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "        print('Training loss: ', loss_fn(model(X), Y))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "ae8ca4686cf6a68f6c9ca93bf3d227abe96c2201",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gd8tiT_q-7wa",
        "outputId": "cefb1b93-aad4-4a1b-c479-47d1bceafb32"
      },
      "source": [
        "# Train the model for 100 epochs\n",
        "fit(100 , model , loss_fn, optimizer)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss:  tensor(8242.7256, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(3400.8623, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1468.3066, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(682.9309, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(353.1192, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(206.6797, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(135.9190, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(97.7909, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(74.7572, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(59.4221, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(48.4816, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(40.3270, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(34.0859, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(29.2300, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(25.4081, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(22.3722, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(19.9394, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(17.9723, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(16.3665, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(15.0418, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(13.9366, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(13.0034, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(12.2057, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(11.5151, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(10.9099, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(10.3731, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(9.8915, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(9.4549, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(9.0554, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(8.6869, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(8.3443, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(8.0239, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(7.7228, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(7.4384, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(7.1688, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(6.9125, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(6.6683, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(6.4350, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(6.2118, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(5.9981, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(5.7931, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(5.5964, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(5.4075, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(5.2259, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(5.0513, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(4.8834, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(4.7219, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(4.5665, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(4.4169, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(4.2729, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(4.1343, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(4.0008, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(3.8723, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(3.7485, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(3.6293, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(3.5145, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(3.4040, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(3.2976, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(3.1950, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(3.0963, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(3.0012, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(2.9096, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(2.8214, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(2.7364, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(2.6545, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(2.5757, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(2.4998, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(2.4267, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(2.3562, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(2.2884, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(2.2230, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(2.1601, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(2.0995, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(2.0411, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.9849, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.9307, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.8785, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.8283, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.7799, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.7332, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.6883, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.6451, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.6034, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.5633, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.5247, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.4874, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.4516, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.4171, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.3838, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.3518, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.3209, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.2912, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.2626, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.2350, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.2084, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.1828, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.1582, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.1345, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.1116, grad_fn=<MseLossBackward>)\n",
            "Training loss:  tensor(1.0896, grad_fn=<MseLossBackward>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "32588a47d0478772a1f08fa55874a322630bd0b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3Bf-Emn-7wj",
        "outputId": "dea6385f-861b-4877-a388-868b39ed4c9b"
      },
      "source": [
        "# Generate predictions\n",
        "preds = model(X)\n",
        "preds"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 57.2305,  70.3501],\n",
              "        [ 82.0365,  99.9552],\n",
              "        [118.9766, 134.5175],\n",
              "        [ 21.1571,  37.4559],\n",
              "        [101.6371, 117.5808],\n",
              "        [ 57.2305,  70.3501],\n",
              "        [ 82.0365,  99.9552],\n",
              "        [118.9766, 134.5175],\n",
              "        [ 21.1571,  37.4559],\n",
              "        [101.6371, 117.5808],\n",
              "        [ 57.2305,  70.3501],\n",
              "        [ 82.0365,  99.9552],\n",
              "        [118.9766, 134.5175],\n",
              "        [ 21.1571,  37.4559],\n",
              "        [101.6371, 117.5808]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "12d757c0f37c2e3af65cf9d4b59878cc10c65acf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gDGmiHl-7wr",
        "outputId": "511dc5e0-88ea-4e3a-db84-5a8265c77655"
      },
      "source": [
        "# Compare with targets\n",
        "targets"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 56.,  70.],\n",
              "       [ 81., 101.],\n",
              "       [119., 133.],\n",
              "       [ 22.,  37.],\n",
              "       [103., 119.],\n",
              "       [ 56.,  70.],\n",
              "       [ 81., 101.],\n",
              "       [119., 133.],\n",
              "       [ 22.,  37.],\n",
              "       [103., 119.],\n",
              "       [ 56.,  70.],\n",
              "       [ 81., 101.],\n",
              "       [119., 133.],\n",
              "       [ 22.,  37.],\n",
              "       [103., 119.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "2448d9832722f4f2813f8bd80b91daefd901dc2e",
        "id": "b9nvUidI-7xD"
      },
      "source": [
        "Now we can define the model, optimizer and loss function exactly as before."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAyCq48TMlWJ"
      },
      "source": [
        "#Exercise 1:\n",
        " Try Linear Regression just using numpy (Without Tensorflow/Pytorch or other torch library). You can optionally use sklearn (if you want)\n",
        "#Exercise 2:\n",
        " Try Linear regression on same prediction data using Tensorflow\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HX1IlZEpo2qy"
      },
      "source": [
        "# Ex 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMd8tLFqo2qz"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "model1 = LinearRegression()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8Xr48Aoo2qz"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_Train,X_Test,Y_Train,Y_Test = train_test_split(inputs,targets,test_size=0.2,random_state=132)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2APvhCbvo2q0",
        "outputId": "3d0f80b0-c4df-4499-9a50-0e57beac7c51"
      },
      "source": [
        "model1.fit(X_Train,Y_Train)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y50cp23Fo2q0"
      },
      "source": [
        "Y_pred = model1.predict(X_Test)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-awndD_o2q1",
        "outputId": "8dff5e9f-43ba-4540-d0ea-8b0e629b089c"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "print(mean_squared_error(Y_Test,Y_pred))\n",
        "Y_pred,Y_Test"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.45185506\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[118.66335 , 133.02362 ],\n",
              "        [ 57.141125,  69.92001 ],\n",
              "        [ 20.867579,  37.07937 ]], dtype=float32), array([[119., 133.],\n",
              "        [ 56.,  70.],\n",
              "        [ 22.,  37.]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}
